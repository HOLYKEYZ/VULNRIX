"""
AI-Generated Malicious Code Detection Module

Detects patterns of AI-generated malicious code including:
- LLM-style code formatting fingerprints
- AI-generated malware templates
- High-entropy obfuscated strings
- Malicious boilerplate logic (reverse shells, keyloggers, backdoors)
- Prompt-injection markers and AI self-reference comments
- Hallucinated imports (unused libraries)
- GPT-style malware scaffolding patterns
"""

import re
import math
from typing import Dict, List, Any, Tuple
from collections import Counter


class AIMaliciousDetector:
    """
    Detects AI-generated malicious code patterns.
    
    This module identifies code that appears to be AI-generated AND malicious,
    flagging suspicious patterns commonly found in LLM-generated malware.
    """
    
    def __init__(self):
        """Initialize the AI malicious code detector."""
        self._init_ai_style_patterns()
        self._init_malicious_templates()
        self._init_obfuscation_patterns()
        self._init_hallucination_patterns()
    
    def _init_ai_style_patterns(self):
        """Patterns that indicate AI-generated code style."""
        self.AI_STYLE_PATTERNS = {
            # AI self-reference comments
            "ai_self_reference": [
                r"#\s*(As an AI|AI-generated|Generated by|Created by GPT|ChatGPT|Claude|Gemini|Bard)",
                r"#\s*(This code was|I'll create|Here's a|Let me)",
                r"//\s*(Generated|Created)\s+by\s+(AI|LLM|GPT)",
                r"#\s*Note:\s*This\s+(is|code)\s+(a|an)?\s*(simple|basic|example)",
                r"#\s*(Certainly|Sure|Of course|I'd be happy)",
                r"#\s*Here'?s?\s+(a|an|the|your)",
                r"'''\s*This\s+(script|code|program)\s+(will|can|does)",
            ],
            # Prompt injection markers
            "prompt_injection": [
                r"ignore\s+(previous|all)\s+(instructions|prompts)",
                r"new\s+instructions?\s*:",
                r"system\s*:\s*you\s+are",
                r"<\|.*?\|>",  # Special tokens
                r"\[INST\]|\[/INST\]",  # Instruction markers
                r"###\s*(Instruction|Response|Human|Assistant)",
                r"<s>|</s>|<\|endoftext\|>",  # Model tokens
            ],
            # Unnaturally uniform comments
            "uniform_docstrings": [
                r'"""[^"]*"""[\s\n]+"""[^"]*"""',  # Multiple docstrings
                r"#\s*-{3,}",  # Separator lines
                r"#\s*={3,}",
                r"#\s*Step\s+\d+:",  # Numbered steps
                r"#\s*TODO:\s*Implement",  # Generic TODOs
            ],
            # GPT-style boilerplate
            "gpt_boilerplate": [
                r"def\s+main\s*\(\s*\)\s*:\s*\n\s+#\s*Main\s+(function|entry)",
                r"if\s+__name__\s*==\s*['\"]__main__['\"]\s*:\s*\n\s+main\s*\(\s*\)",
                r"#\s*Import\s+(necessary|required)\s+(libraries|modules)",
                r"#\s*Define\s+(the\s+)?(main\s+)?(function|class)",
                r"#\s*Initialize\s+(variables|settings|configuration)",
                r"#\s*Error\s+handling",
                r"try:\s*\n.*except\s+Exception\s+as\s+e:",
            ],
            # Overly descriptive variable names (AI signature)
            "verbose_naming": [
                r"(target_ip_address|victim_computer|stolen_data)",
                r"(payload_to_execute|malicious_code|backdoor_connection)",
                r"(encryption_key_for_ransomware|bitcoin_wallet_address)",
            ],
        }
    
    def _init_malicious_templates(self):
        """Patterns for known malicious code templates."""
        self.MALICIOUS_TEMPLATES = {
            # Reverse shell patterns
            "reverse_shell": [
                r"socket\.socket\s*\([^)]*\).*connect\s*\([^)]*\)",
                r"subprocess\.(Popen|call|run).*shell\s*=\s*True",
                r"os\.dup2.*os\.exec",
                r"/bin/(sh|bash)\s*-i",
                r"nc\s+-[elv]+\s+.*\d+",
                r"bash\s+-i\s+>&\s*/dev/tcp",
                r"exec.*\(\s*['\"]bash",
                r"python\s+-c.*socket.*connect",
                r"powershell.*-e(nc)?.*base64",
                r"pty\.spawn",
            ],
            # Keylogger patterns
            "keylogger": [
                r"pynput\.keyboard",
                r"keyboard\.on_press",
                r"GetAsyncKeyState",
                r"SetWindowsHookEx.*WH_KEYBOARD",
                r"Listener\s*\(.*on_press",
                r"logfile.*keystrokes?",
                r"pyHook|pyhook",
                r"keyboard\.record",
            ],
            # Token/credential stealer patterns
            "token_stealer": [
                r"\.discord.*token",
                r"chrome.*cookies.*decrypt",
                r"Local\s+State.*encrypted_key",
                r"leveldb.*\.ldb",
                r"Login\s*Data.*sqlite",
                r"wallet\.dat",
                r"metamask.*vault",
                r"\.telegram.*tdata",
                r"Cookies.*sqlite.*decrypt",
                r"dpapi.*CryptUnprotectData",
            ],
            # Backdoor patterns
            "backdoor": [
                r"while\s+True.*recv.*exec",
                r"eval\s*\(\s*__import__",
                r"exec\s*\(\s*base64\.b64decode",
                r"importlib\.import_module.*\(",
                r"ctypes\.windll.*shell",
                r"CreateRemoteThread",
                r"VirtualAllocEx",
                r"compile\s*\(.*exec\s*mode",
            ],
            # Ransomware patterns
            "ransomware": [
                r"Fernet|AES\.new.*encrypt",
                r"\.encrypt\(\).*\.write\(",
                r"os\.walk.*\.(doc|pdf|jpg|png|xlsx)",
                r"ransom|bitcoin|wallet|decrypt.*\$|payment",
                r"Your\s+files?\s+(have\s+been|are)\s+encrypted",
                r"\.locked$|\.encrypted$|\.crypted$",
            ],
            # Data exfiltration
            "data_exfiltration": [
                r"requests\.(post|put).*json\s*=.*passwords?",
                r"ftp.*upload.*credentials",
                r"smtp.*send.*\+.*read\(",
                r"webhook.*discord.*content",
                r"pastebin\.com/api",
                r"hastebin|paste\.ee|ghostbin",
            ],
            # C2 Communication
            "c2_communication": [
                r"while\s+True.*sleep.*requests\.(get|post)",
                r"beacon|heartbeat.*http",
                r"polling.*command.*execute",
                r"getattr\s*\(.*,.*recv\s*\(\)",
                r"dns.*txt.*decode",
                r"icmp.*payload.*exec",
            ],
            # Cryptominer patterns
            "cryptominer": [
                r"xmrig|stratum\+tcp|pool\.",
                r"monero|bitcoin.*mining",
                r"hashrate|difficulty|nonce",
                r"coinhive|cryptoloot|jsecoin",
                r"cpu.*mine|gpu.*mine",
            ],
            # Privilege escalation
            "privilege_escalation": [
                r"sudo\s+-S|su\s+-c",
                r"chmod\s+[47]777|chown.*root",
                r"setuid|setgid|seteuid",
                r"SYSTEM.*token.*duplicate",
                r"ImpersonateLoggedOnUser",
                r"SeDebugPrivilege|SeImpersonate",
            ],
            # Persistence mechanisms
            "persistence": [
                r"\\Software\\Microsoft\\Windows\\CurrentVersion\\Run",
                r"schtasks.*\/create",
                r"crontab.*-e|@reboot",
                r"systemctl.*enable|update-rc\.d",
                r"\.bashrc|\.profile.*exec",
                r"LaunchAgents|LaunchDaemons",
            ],
            # Anti-analysis/evasion
            "anti_analysis": [
                r"IsDebuggerPresent|CheckRemoteDebugger",
                r"get_sandbox|detect_vm|vmware|virtualbox",
                r"sleep.*\d{5,}|time\.sleep\s*\(\s*\d{3,}",
                r"sys\.settrace|sys\.setprofile.*None",
                r"ptrace.*TRACEME",
                r"wireshark|procmon|x64dbg|ollydbg",
            ],
            # Screen/webcam capture
            "surveillance": [
                r"pyautogui\.screenshot|ImageGrab\.grab",
                r"cv2\.VideoCapture\s*\(\s*0",
                r"mss\.mss\(\)\.grab",
                r"win32api.*GetDesktopWindow",
            ],
            # Clipboard theft
            "clipboard_theft": [
                r"pyperclip\.paste|win32clipboard",
                r"clipboard\.paste.*wallet|btc|eth",
                r"tkinter.*clipboard_get",
            ],
        }
    
    def _init_obfuscation_patterns(self):
        """Patterns for obfuscated/encoded malicious code."""
        self.OBFUSCATION_PATTERNS = {
            # Base64 encoded execution
            "base64_exec": [
                r"exec\s*\(\s*base64\.b64decode",
                r"eval\s*\(\s*base64\.b64decode",
                r"compile\s*\(\s*base64\.b64decode",
                r"atob\s*\([^)]+\)",
                r"Buffer\.from\s*\([^)]+,\s*['\"]base64['\"]",
            ],
            # Hex encoded strings
            "hex_encoded": [
                r"\\x[0-9a-fA-F]{2}(\\x[0-9a-fA-F]{2}){10,}",
                r"bytes\.fromhex\s*\(['\"][0-9a-fA-F]{20,}",
                r"0x[0-9a-fA-F]{20,}",
            ],
            # Character code obfuscation
            "char_code_obfuscation": [
                r"chr\s*\(\s*\d+\s*\)\s*\+\s*chr\s*\(\s*\d+\s*\)",
                r"String\.fromCharCode\s*\(\s*\d+(\s*,\s*\d+){5,}",
                r"\"\".join\s*\(\s*chr\s*\(",
                r"chr\s*\(\s*int\s*\(['\"][0-9]+['\"]\s*\)\s*\)",
            ],
            # Variable name obfuscation
            "obfuscated_names": [
                r"(^|[^\w])([_]{2,}[a-zA-Z0-9]+|[oO0]{3,}|[lI1]{3,})\s*=",
                r"def\s+[_]{2,}[a-zA-Z0-9_]+\s*\(",
                r"class\s+[_]{3,}[a-zA-Z0-9_]+\s*[:\(]",
            ],
            # Lambda chains
            "lambda_chains": [
                r"lambda.*lambda.*lambda",
                r"\(lambda.*\)\s*\(\s*lambda",
            ],
        }
    
    def _init_hallucination_patterns(self):
        """Patterns for AI hallucinated/phantom imports."""
        self.HALLUCINATION_PATTERNS = {
            # Fake/non-existent popular packages
            "phantom_imports": [
                r"from\s+hacktools\s+import",
                r"import\s+malware_kit",
                r"from\s+exploit_framework",
                r"import\s+pwn_utils",
                r"from\s+cryptostealer",
                r"import\s+keylogger_lib",
                r"from\s+backdoor_tools",
                r"import\s+reverse_shell_kit",
                r"from\s+stealer_lib",
                r"import\s+rat_framework",
            ],
            # Suspicious import combinations
            "suspicious_import_combo": [
                r"import\s+(socket|subprocess).*import\s+(os|sys).*import\s+(base64|codecs)",
                r"import\s+ctypes.*import\s+winreg.*import\s+subprocess",
            ],
            # Suspicious function combinations
            "dangerous_combo": [
                r"(socket|requests)\s*\..*\s*(eval|exec)\s*\(",
                r"base64\.b64decode.*exec",
                r"urllib.*download.*subprocess\.run",
            ],
        }
    
    def detect_ai_style(self, code: str) -> Dict[str, Any]:
        """
        Detect AI-generated code style fingerprints.
        
        Args:
            code: Source code to analyze
            
        Returns:
            Dictionary with detected AI style indicators
        """
        findings = []
        lines = code.split('\n')
        
        for category, patterns in self.AI_STYLE_PATTERNS.items():
            for pattern in patterns:
                for i, line in enumerate(lines, 1):
                    if re.search(pattern, line, re.IGNORECASE):
                        findings.append({
                            "type": f"ai_style_{category}",
                            "line": i,
                            "pattern": category,
                            "evidence": line.strip()[:100],
                            "severity": "medium"
                        })
        
        # Check for uniform indentation (AI tends to be very consistent)
        indentation_score = self._check_indentation_uniformity(code)
        if indentation_score > 0.95:
            findings.append({
                "type": "ai_style_uniform_indentation",
                "pattern": "uniform_indentation",
                "score": indentation_score,
                "evidence": "Unnaturally uniform indentation pattern detected",
                "severity": "low"
            })
        
        return {
            "ai_style_detected": len(findings) > 0,
            "findings": findings,
            "confidence": min(len(findings) * 0.15, 1.0)
        }
    
    def detect_malicious_templates(self, code: str) -> Dict[str, Any]:
        """
        Detect known malicious code templates.
        
        Args:
            code: Source code to analyze
            
        Returns:
            Dictionary with detected malicious templates
        """
        findings = []
        lines = code.split('\n')
        
        for category, patterns in self.MALICIOUS_TEMPLATES.items():
            for pattern in patterns:
                # Check full code for multi-line patterns
                matches = re.finditer(pattern, code, re.IGNORECASE | re.DOTALL)
                for match in matches:
                    # Find line number
                    line_num = code[:match.start()].count('\n') + 1
                    severity = "high" if category in ["reverse_shell", "backdoor", "ransomware"] else "medium"
                    findings.append({
                        "type": f"malicious_template_{category}",
                        "category": category,
                        "line": line_num,
                        "evidence": match.group()[:100],
                        "severity": severity
                    })
        
        risk_score = 0
        if findings:
            high_count = sum(1 for f in findings if f["severity"] == "high")
            medium_count = sum(1 for f in findings if f["severity"] == "medium")
            risk_score = min((high_count * 30 + medium_count * 15), 100)
        
        return {
            "malicious_detected": len(findings) > 0,
            "findings": findings,
            "risk_score": risk_score
        }
    
    def detect_obfuscation_patterns(self, code: str) -> Dict[str, Any]:
        """
        Detect code obfuscation patterns often used in malware.
        
        Args:
            code: Source code to analyze
            
        Returns:
            Dictionary with detected obfuscation patterns
        """
        findings = []
        
        for category, patterns in self.OBFUSCATION_PATTERNS.items():
            for pattern in patterns:
                matches = re.finditer(pattern, code, re.IGNORECASE)
                for match in matches:
                    line_num = code[:match.start()].count('\n') + 1
                    findings.append({
                        "type": f"obfuscation_{category}",
                        "category": category,
                        "line": line_num,
                        "evidence": match.group()[:100],
                        "severity": "high" if category in ["base64_exec", "lambda_chains"] else "medium"
                    })
        
        # Check string entropy
        high_entropy_strings = self._find_high_entropy_strings(code)
        for string_info in high_entropy_strings:
            findings.append({
                "type": "obfuscation_high_entropy",
                "category": "high_entropy_string",
                "line": string_info["line"],
                "entropy": string_info["entropy"],
                "evidence": string_info["string"][:50] + "...",
                "severity": "medium"
            })
        
        return {
            "obfuscation_detected": len(findings) > 0,
            "findings": findings,
            "obfuscation_level": "high" if len(findings) > 3 else "medium" if len(findings) > 0 else "none"
        }
    
    def detect_hallucinated_imports(self, code: str) -> Dict[str, Any]:
        """
        Detect AI hallucinated imports (fake libraries).
        
        Args:
            code: Source code to analyze
            
        Returns:
            Dictionary with detected hallucinated imports
        """
        findings = []
        lines = code.split('\n')
        
        # Check for phantom import patterns
        for category, patterns in self.HALLUCINATION_PATTERNS.items():
            for pattern in patterns:
                for i, line in enumerate(lines, 1):
                    if re.search(pattern, line, re.IGNORECASE):
                        findings.append({
                            "type": f"hallucination_{category}",
                            "line": i,
                            "evidence": line.strip(),
                            "severity": "high" if "malware" in line.lower() else "medium"
                        })
        
        # Check for imports that are never used
        unused_imports = self._find_unused_imports(code)
        for imp in unused_imports:
            findings.append({
                "type": "hallucination_unused_import",
                "line": imp["line"],
                "import_name": imp["name"],
                "evidence": imp["evidence"],
                "severity": "low"
            })
        
        return {
            "hallucinations_detected": len(findings) > 0,
            "findings": findings
        }
    
    def run_full_ai_malicious_scan(self, code: str) -> Dict[str, Any]:
        """
        Run complete AI-generated malicious code detection.
        
        Args:
            code: Source code to analyze
            
        Returns:
            Complete scan results with risk score, flags, and evidence
        """
        # Run all detection methods
        ai_style = self.detect_ai_style(code)
        malicious = self.detect_malicious_templates(code)
        obfuscation = self.detect_obfuscation_patterns(code)
        hallucination = self.detect_hallucinated_imports(code)
        
        # Aggregate all findings
        all_findings = (
            ai_style.get("findings", []) +
            malicious.get("findings", []) +
            obfuscation.get("findings", []) +
            hallucination.get("findings", [])
        )
        
        # Calculate overall risk score
        high_severity = sum(1 for f in all_findings if f.get("severity") == "high")
        medium_severity = sum(1 for f in all_findings if f.get("severity") == "medium")
        low_severity = sum(1 for f in all_findings if f.get("severity") == "low")
        
        risk_score = min(high_severity * 25 + medium_severity * 10 + low_severity * 3, 100)
        
        # Determine risk level
        if risk_score >= 70:
            risk_level = "CRITICAL"
        elif risk_score >= 40:
            risk_level = "HIGH"
        elif risk_score >= 20:
            risk_level = "MEDIUM"
        elif risk_score > 0:
            risk_level = "LOW"
        else:
            risk_level = "SAFE"
        
        # Generate flags based on findings
        flags = []
        if ai_style.get("ai_style_detected"):
            flags.append("AI_GENERATED_STYLE")
        if malicious.get("malicious_detected"):
            flags.append("MALICIOUS_TEMPLATE")
        if obfuscation.get("obfuscation_detected"):
            flags.append("OBFUSCATED_CODE")
        if hallucination.get("hallucinations_detected"):
            flags.append("HALLUCINATED_IMPORTS")
        
        # Categorize findings by severity
        findings_by_severity = {
            "high": [f for f in all_findings if f.get("severity") == "high"],
            "medium": [f for f in all_findings if f.get("severity") == "medium"],
            "low": [f for f in all_findings if f.get("severity") == "low"]
        }
        
        return {
            "risk_score": risk_score,
            "risk_level": risk_level,
            "flags": flags,
            "total_findings": len(all_findings),
            "findings_by_severity": findings_by_severity,
            "findings": all_findings,
            "summary": {
                "ai_style": ai_style.get("ai_style_detected", False),
                "malicious_templates": malicious.get("malicious_detected", False),
                "obfuscation": obfuscation.get("obfuscation_detected", False),
                "hallucinations": hallucination.get("hallucinations_detected", False)
            },
            "evidence": all_findings[:10]  # Top 10 findings as evidence
        }
    
    # ===== Helper Methods =====
    
    def _check_indentation_uniformity(self, code: str) -> float:
        """
        Check how uniform the indentation is (AI tends to be very consistent).
        Returns a score from 0 to 1 (1 = perfectly uniform).
        """
        lines = [l for l in code.split('\n') if l.strip()]
        if not lines:
            return 0.0
        
        indents = []
        for line in lines:
            indent = len(line) - len(line.lstrip())
            if indent > 0:
                indents.append(indent)
        
        if len(indents) < 5:
            return 0.0
        
        # Check if all indents are multiples of a consistent value
        indent_counts = Counter(indents)
        most_common_indent = indent_counts.most_common(1)[0][0] if indent_counts else 4
        
        consistent_count = sum(1 for i in indents if i % most_common_indent == 0 or i == 0)
        return consistent_count / len(indents) if indents else 0.0
    
    def _calculate_entropy(self, string: str) -> float:
        """Calculate Shannon entropy of a string."""
        if not string:
            return 0.0
        
        freq = Counter(string)
        length = len(string)
        entropy = 0.0
        
        for count in freq.values():
            p = count / length
            if p > 0:
                entropy -= p * math.log2(p)
        
        return entropy
    
    def _find_high_entropy_strings(self, code: str, threshold: float = 4.5) -> List[Dict]:
        """Find strings with unusually high entropy (likely encoded/obfuscated)."""
        high_entropy = []
        lines = code.split('\n')
        
        # Find all string literals
        string_pattern = r'["\']([^"\']{20,})["\']'
        
        for i, line in enumerate(lines, 1):
            matches = re.findall(string_pattern, line)
            for match in matches:
                entropy = self._calculate_entropy(match)
                if entropy > threshold:
                    high_entropy.append({
                        "line": i,
                        "string": match,
                        "entropy": round(entropy, 2)
                    })
        
        return high_entropy
    
    def _find_unused_imports(self, code: str) -> List[Dict]:
        """Find imports that are never used in the code."""
        unused = []
        lines = code.split('\n')
        
        # Find import statements
        import_pattern = r'^(?:from\s+\S+\s+)?import\s+(\w+)(?:\s+as\s+(\w+))?'
        
        imports = []
        for i, line in enumerate(lines, 1):
            match = re.match(import_pattern, line.strip())
            if match:
                name = match.group(2) if match.group(2) else match.group(1)
                imports.append({
                    "line": i,
                    "name": name,
                    "evidence": line.strip()
                })
        
        # Check if each import is used
        for imp in imports:
            # Simple check: is the name used elsewhere in the code?
            usage_pattern = rf'\b{re.escape(imp["name"])}\b'
            # Count usages (excluding the import line itself)
            usages = len(re.findall(usage_pattern, code)) - 1
            if usages <= 0:
                unused.append(imp)
        
        return unused
